{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is day three of a three day event, held during [Kaggle CareerCon 2019](https://www.kaggle.com/careercon2019). Each day we’ll learn about a new part of developing an API and put it into practice. By day 3, you’ll have written and deployed an API of your very own!\n",
    "\n",
    " * **[Day 1: The Basics of Rest APIs – What They Are and How to Design One](https://www.kaggle.com/rtatman/careercon-intro-to-apis).** By the end of this day you’ll have written the OpenAPI specification for your API. \n",
    " * **[Day 2: How to Make an API for an Existing Python Machine Learning Project](https://www.kaggle.com/rtatman/careercon-making-an-app-from-your-modeling-code).** By the end of this day, you’ll have a Flask app that you can use to serve your model.\n",
    " * **[Day 3: How to deploy your API on your choice of services – Heroku or Google Cloud](https://www.kaggle.com/rtatman/careercon-deploying-apis-on-heroku-appengine/).** By the end of this day, you’ll have deployed your model and will be able to actually use your API! (Note that, in order to use Google Cloud, you’ll need to create a billing account, which requires a credit card. If you don’t have access to a credit, you can still use Heroku.)\n",
    "\n",
    "___\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Today I'm going to walk you through how to deploy your API using either **Heroku** or **AppEngine**! They're fairly similar services, but I wanted to give you a chance to use both and see what you prefer. By using two services I can also show you how different platforms expect a different file structure for your apps.\n",
    "\n",
    "* **Heroku** is a platform as a service that's designed specifically for serving applications. You don't need to have a credit card to create an API on Heroku, but you'll be limited by what's offered through the free tier.\n",
    "* **AppEngine** is part of Google Cloud and is also a way to serve apps. You do need a credit card to create an app on AppEngine, but once it's set up you can [go to your appengine settings](https://console.cloud.google.com/appengine/settings) and set the daily spending limit to 0. This will keep you from being charged.\n",
    "\n",
    "I'll start with Heroku, then talk about AppEngine and finally show you how to query your API using Python. :)\n",
    "\n",
    "# Heroku\n",
    "\n",
    "## Edit files on GitHub\n",
    "\n",
    "For your conviencice, I've created an extrememly simple sample app on GitHub: https://github.com/rctatman/minimal_flask_example_heroku. You'll want to head over to GitHub, fork this repo and then edit the relevant files for your specific app. \n",
    "\n",
    "Here's a quick guide to each of the files and information that tells you which to edit:\n",
    "\n",
    "### Files you'll put the code you wrote yesterday into \n",
    "\n",
    "[In yesterday's notebook](https://www.kaggle.com/rtatman/careercon-making-an-app-from-your-modeling-code), as the very last exercise we wrote two cells of code, each of which will be a single file. \n",
    "\n",
    "* **serve.py**: This is the file you should put the code from the first cell in; this is where you'll define the functions that will read in your trained models.\n",
    "* **script.py**: This is where you'll put the code from your second notebook. This is what will define the behavior of our different endpoints.  \n",
    "\n",
    "### Files you'll need to add\n",
    "\n",
    "If you are going to use a pre-trained model, be sure to add it to your repo so that you can read it in. If you like, you can store your models in a new file, but if you do this be sure to update the file path of the code that you read them with. So if you have a model called \"my_model.pkl\" in a folder called \"models\", you'll need to update the code that reads it in from this:\n",
    "\n",
    "\n",
    "```\n",
    "pickle.load(open(\"my_model.pkl\", \"rb\")\n",
    "```\n",
    "\n",
    "to this:\n",
    "\n",
    "```\n",
    "pickle.load(open(\"models/my_model.pkl\", \"rb\")\n",
    "```\n",
    "\n",
    "### Files you'll need to edit\n",
    "\n",
    "* **README**: This is the file you're currently reading. You'll probably want to update this to have information about your specific API and how to use it.\n",
    "* **openapi.yaml**: You can relace this file with the specification file that we wrote on day one. ([The notebook's here if you need a refresher](https://www.kaggle.com/rtatman/careercon-intro-to-apis)).\n",
    "* **requirements.txt**: This file has information on what packages you use in your app. *You need to make sure that you list every package you import and also gunicorn*. If you remove the line with gunicorn or forget to include a package you import somewhere else, you'll get an error when you try to run your app. \n",
    "* **runtime.txt**: This file tells Heroku which version of Python to use to run your app. You'll only need to update this file if you pickled your model file using a different version of Python & that's causing your code to break. \n",
    "\n",
    "\n",
    "### File you don't need to edit\n",
    "\n",
    "* **LICENSE**: This file is the license your code is released under. If you don't include a license, other folks won't be able to reuse your code. If you fork this repository for your own work, you'll need to keep the license. I've used Apache 2.0 here because that's the same license as public Kaggle Kernels. \n",
    "* **Procfile**: This file is required by Heroku. It tells Heroku how to run your application. You probably don't need to change this file. \n",
    "\n",
    "\n",
    "## Deploy to Heroku\n",
    "\n",
    "Once you've edited your files, you're ready to deploy to [Heroku](www.heroku.com). \n",
    "\n",
    "* Create a new account or sign into your existing account\n",
    "* Go to https://dashboard.heroku.com/apps\n",
    "* Create your app\n",
    "    * Click on “create new app”\n",
    "    * Give it a name & choose your region\n",
    "    * Hit “create app”\n",
    "* Connect to GitHub repo \n",
    "    * Click on the Deploy tab\n",
    "    * CLick on Connect GitHub & search for the repo you want to add (make sure you've forked the repo; you'll only be able to connect to a GitHub repo you own)\n",
    "* Deploy your app\n",
    "    * Next to “Manual deploy” hit “Deploy Branch”\n",
    "    * If you hit “open app”, you should open a new browser page that points to the URL your app  is served from. (Unless you put something at the endpoint \"\\\" it will probably just be a 404 page.)\n",
    "    \n",
    "And that's it! Your app is live. :)\n",
    "\n",
    "> **What if you run into trouble?** If your app isn't working, click on the [MORE] button in the upper right hand corner, then on \"View logs\". This will show a detailed log of whatever went wrong."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AppEngine\n",
    "\n",
    "\n",
    "For your convenience, I've created an extremely simple sample app on GitHub: https://github.com/rctatman/minimal_flask_example_appengine. You'll want to head over to GitHub, fork this repo and then edit the relevant files for your specific app. \n",
    "\n",
    "Here's a quick guide to each of the files and information that tells you which to edit. Note that this is *different* from the files for Heroku; the two different services expect different file configurations.\n",
    "\n",
    "## Edit files on GitHub\n",
    "\n",
    "### Files you'll put the code you wrote yesterday into \n",
    "\n",
    "[In yesterday's notebook](https://www.kaggle.com/rtatman/careercon-making-an-app-from-your-modeling-code), as the very last exercise we wrote two cells of code, each of which will be a single file. \n",
    "\n",
    "* **serve.py**: This is the file you should put the code from the first cell in; this is where you'll define the functions that will read in your trained models.\n",
    "* **main.py**: This is where you'll put the code from your second notebook. This is what will define the behavior of our different endpoints.  \n",
    "\n",
    "### Files you'll need to add\n",
    "\n",
    "If you are going to use a pre-trained model, be sure to add it to your repo so that you can read it in. If you like, you can store your models in a new file, but if you do this be sure to update the file path of the code that you read them with. So if you have a model called \"my_model.pkl\" in a folder called \"models\", you'll need to update the code that reads it in from this:\n",
    "\n",
    "\n",
    "```\n",
    "pickle.load(open(\"my_model.pkl\", \"rb\")\n",
    "```\n",
    "\n",
    "to this:\n",
    "\n",
    "```\n",
    "pickle.load(open(\"models/my_model.pkl\", \"rb\")\n",
    "```\n",
    "\n",
    "### Files you'll need to edit\n",
    "\n",
    "* **README**: This is the file you're currently reading. You'll probably want to update this to have information about your specific API and how to use it.\n",
    "* **openapi.yaml**: You can relace this file with the specification file that we wrote on day one. ([The notebook's here if you need a refresher](https://www.kaggle.com/rtatman/careercon-intro-to-apis)).\n",
    "* **requirements.txt**: This file has information on what packages you use in your app. It's currently empty becuase I didn't import any packages, but you'll need to include all the packages you use, one per line as show below. If you forget to include a package you import somewhere else, you'll get an error when you try to run your app.\n",
    "\n",
    "```\n",
    "numpy\n",
    "pandas\n",
    "future\n",
    "```\n",
    "\n",
    "### Files you don't need to edit\n",
    "\n",
    "* **LICENSE**: This file is the license your code is released under. If you don't include a license, other folks won't be able to reuse your code. If you fork this repository for your own work, you'll need to keep the license. I've used Apache 2.0 here because that's the same license as public Kaggle Kernels. \n",
    "* **app.yaml**: This file tells AppEngine which version of Python to use to run your app. You don't need to edit this.\n",
    "* **index.yaml**: This file is required by AppEngine and tells it how to index the data you send to Datastore. Since we're not using Datastore, we can just ignore this file.\n",
    "\n",
    "## Deploy to AppEngine\n",
    "\n",
    "Now you're ready to deploy your app! We're going to be interacting with AppEngine via Cloud Shell. You can use the GUI as well, but I personally like Cloud Shell. :)\n",
    "\n",
    "> *Don't forget to sign into your GCP account or create one if you don't have one! You'll also want to set up a billing account you can connect your project to in order to build your app.*\n",
    "\n",
    "I know this looks like a lot of steps, but I've tried to be very clear so you know what to do at each step. \n",
    "\n",
    "* Copy your repo into your Cloud Shell VM\n",
    "    * Either edit and use the button in the GitHub README OR \n",
    "    * Go to the Cloud Shell (https://console.cloud.google.com/cloudshell/editor) and clone it yourself: git clone [GITHUB-URL]\n",
    "    * Move into the repo by running `cd [NAME-OF-REPO]` in the black console at the bottom of the screen, which is where you'll run all the commands from here on out. (You'll need to replace [NAME-OF-REPO] with your actual repo.)\n",
    "* Launch your app locally (helpful for testing)\n",
    "    * Use this command to test deploy your app: \n",
    "        `dev_appserver.py ./app.yaml`\n",
    "    * Once you see output like: \"Booting worker with pid\" in the command line, you can see your app by hitting the button that looks like <> in a browser window at the top right hand side of your screen. This will open a new tab running your app. If you haven't put anything at the \"\\\" end point, this will just a 404. \n",
    "    * Use `CTRL + C` to close your app\n",
    "* Create a project & enable billing.\n",
    "    * Run these commands, replacing [YOUR-PROJECT-ID] with your actual product ID. \n",
    "        * `gcloud projects create [YOUR-PROJECT-ID]`\n",
    "        * `gcloud config set project [YOUR-PROJECT-ID]`\n",
    "    * You'll see your project id in yellow\n",
    "    * Enable cloud build by going to this URL & clicking \"enable\", then following the prompts: https://console.developers.google.com/apis/library/cloudbuild.googleapis.com. \n",
    "* Launch the app!\n",
    "    * Deploy your app by running this command:\n",
    "        * `gcloud app deploy ./index.yaml ./app.yaml`\n",
    "    * Pick a region (I'd recommend one closer to you to reduce latency)\n",
    "    * Enter \"y\" when asked whether you want to continue\n",
    "    * After it's finished deploying, your app will be at the URL: https://[YOUR-PROJECT-ID].appspot.com/\n",
    "* You can query your app directly from Cloud Shell! :)\n",
    "    * Run these commands to query your app, replacing the [text in brackets] as applicable for your project.\n",
    "        * `python`\n",
    "        * `import requests`\n",
    "        * `requests.[METHOD]('https://[YOUR-PROJECT-ID].appspot.com/[YOUR-ENDPOINT-NAME], json=[JSON-TO-SEND]).json()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'requests' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-bb1dd8785bb7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mrequests\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpost\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'https://api-test-project-236423.appspot.com/api'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_text\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'requests' is not defined"
     ]
    }
   ],
   "source": [
    "requests.post('https://api-test-project-236423.appspot.com/api', json=input_text).text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Querying APIs using requests\n",
    "\n",
    "Ok, now that you've got your app up and running, how do you actually query it? Probably the simplest way to do this from Python is using the requests library. The anatomy of a request is like so:\n",
    "\n",
    "> requests.[method]([url/endpoint], expected_input_type=some_python_object)\n",
    "\n",
    "This will send a request to your API and, hopefully, return a response. If it works, you'll probably just see the response code output: \n",
    "\n",
    "`<Response [200]>`\n",
    "\n",
    "In order to get the data that was returned, you can append `.json()` to parse any JSON that was returned or `.text` just to see the raw strings.\n",
    "\n",
    "Here are some example queries for the sample app I've talked about in my notebooks so far. (Note that I'm only using the free tier of each service to serve these, so if people make a lot of requests and I hit my quota, they'll stop working.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['pandas', 0, 6], ['numpy', 44, 49], ['future', 61, 67]]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "input_text  = \"Pandas is my favorite library. I don't like numpy as much as future.\"\n",
    "\n",
    "# this queries an app I already have running on Heroku\n",
    "# code: https://github.com/rctatman/flask_example_heroku\n",
    "requests.post('http://kaggle-test.herokuapp.com/extractpackages', json=input_text).json()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the AppEngine version, I called my endpoint \"api\" instead of \"extractpackages\" and I'm honestly just too lazy to change it at this point. Otherwise it looks pretty much the same, but with a different URL."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['pandas', 0, 6], ['numpy', 44, 49], ['future', 61, 67]]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# and this queries a pretty much identical app running on AppEngine\n",
    "# code: https://github.com/rctatman/flask_example_appengine\n",
    "requests.post('https://api-test-project-236423.appspot.com/api', json=input_text).json()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And that's it! Over the last three days we've:\n",
    "\n",
    "* Designed an API and written a specification\n",
    "* Prepared our code & models to be put in a Flask App\n",
    "* Written the app itself\n",
    "* Deployed and used our very own APIs\n",
    "\n",
    "I hope you found these notebooks helpful and learned something new about APIs. I'd love to hear about what you all built in the comments!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
